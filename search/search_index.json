{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Raspbernetes","text":"<p>This repo is a declarative implementation of a Kubernetes cluster which follows GitOps princples. It's using the FluxCD.</p>"},{"location":"#mission","title":"Mission","text":"<p>The goal is to demonstrates how to implement enterprise-grade security, observability, and overall cluster config management using GitOps in a Kubernetes cluster.</p>"},{"location":"#story","title":"Story","text":"<p>This project ...</p>"},{"location":"configuration/ip-allocation/","title":"IP Allocation","text":"<p>Work in progress</p> <p>This document is a work in progress.</p>"},{"location":"configuration/ip-allocation/#production-zone-a","title":"Production - Zone A","text":"Application/Node Type IP/CIDR keepalived VIP 192.168.1.200/32 k8s-controlplane-01 Control-Plane Node 192.168.1.121/32 k8s-controlplane-02 Control-Plane Node 192.168.1.122/32 k8s-controlplane-03 Control-Plane Node 192.168.1.123/32 k8s-node-01 Node 192.168.1.131/32 k8s-node-01 Node 192.168.1.132/32 k8s-node-01 Node 192.168.1.133/32 metallb Daemonset 192.168.1.150 &lt;-&gt; 192.168.1.155 istio LoadBalancer 192.168.1.150/32 coredns LoadBalancer 192.168.1.151/32 mosquitto LoadBalancer 192.168.1.152/32 zigbee2mqtt LoadBalancer 192.168.1.153/32 zigbee2mqtt (code-server) LoadBalancer 192.168.1.154/32"},{"location":"configuration/ip-allocation/#production-zone-b","title":"Production - Zone B","text":"Application Type IP/CIDR keepalived VIP 192.168.1.201/32 k8s-controlplane-01 Control-Plane Node 192.168.1.161/32 k8s-controlplane-02 Control-Plane Node 192.168.1.162/32 k8s-controlplane-03 Control-Plane Node 192.168.1.163/32 k8s-node-01 Node 192.168.1.171/32 k8s-node-01 Node 192.168.1.172/32 k8s-node-01 Node 192.168.1.173/32 metallb Daemonset 192.168.1.180 &lt;-&gt; 192.168.1.185 istio LoadBalancer 192.168.1.180/32 coredns LoadBalancer 192.168.1.181/32 mosquitto LoadBalancer 192.168.1.182/32 zigbee2mqtt LoadBalancer 192.168.1.183/32"},{"location":"configuration/ip-allocation/#external-services","title":"External Services","text":"Application Type IP/CIDR Zigbee Controller N/A 192.168.1.165/32 Ender 5 Pro 3D Printer N/A x.x.x.x/32"},{"location":"configuration/pre-rockpi4c/","title":"Rock Pi 4C","text":"<p>The following are prerequisites to create a Kubernetes on the RockPi(s) 4C</p>"},{"location":"configuration/pre-rockpi4c/#hardware","title":"Hardware","text":"<p>Since I decided to use an eMMC module rather than the typical microSD I needed to purchase either a eMMC to USB adapter or eMMC to microSD adapter. I purchased both and they work equally as fine except you can save some $$$ if you choose to purchase the eMMC to microSD adapter.</p> <p>Either can be purchased with the below links:</p> <ul> <li>eMMC microSD adapter</li> <li>eMMC USB3.0 adapter</li> </ul>"},{"location":"configuration/pre-rockpi4c/#instruction","title":"Instruction","text":"<p>When running <code>apt-get upgrade</code> you will get the following error:</p> <pre><code>Err:4 http://apt.radxa.com/buster-stable buster InRelease\n  The following signatures were invalid: EXPKEYSIG 5761288B2B52CC90 Radxa &lt;dev@radxa.com&gt;\nReading package lists... Done\nW: GPG error: http://apt.radxa.com/buster-stable buster InRelease: The following signatures were invalid: EXPKEYSIG 5761288B2B52CC90 Radxa &lt;dev@radxa.com&gt;\nE: The repository 'http://apt.radxa.com/buster-stable buster InRelease' is not signed.\nN: Updating from such a repository can't be done securely, and is therefore disabled by default.\nN: See apt-secure(8) manpage for repository creation and user configuration details.\n</code></pre> <p>To fix this error use the following steps.</p> <p>Install wget</p> <pre><code>sudo apt-get update\nsudo apt-get install -y wget\n</code></pre> <p>Edit /etc/apt/sources.list.d/apt-radxa-com.list</p> <pre><code>deb http://apt.radxa.com/buster-stable/ buster main\ndeb http://apt.radxa.com/buster-testing/ buster main\n</code></pre> <p>Add the public apt-key</p> <pre><code>wget -O - apt.radxa.com/buster-testing/public.key | sudo apt-key add -\nwget -O - apt.radxa.com/buster-stable/public.key | sudo apt-key add -\n</code></pre> <p>You will no longer have the above mentioned issue. Follow instructions here to complete the Kubernetes bootstrap process: https://github.com/raspbernetes/k8s-cluster-installation</p>"},{"location":"configuration/repo-structure/","title":"Flux Repository Structure","text":""},{"location":"configuration/repo-structure/#tldr-quick-start","title":"TL;DR Quick Start","text":"<p>If you're familiar with Kustomize and how it operates within the Flux ecosystem this will provide a quick overview:</p> <pre><code>.\n\u2514\u2500\u2500 k8s/\n    \u251c\u2500\u2500 clusters/\n    \u2502   \u251c\u2500\u2500 production/                         # One folder per cluster.\n\u2502   \u2502   \u251c\u2500\u2500 flux-system/                    # Folder containing flux-system manifests.\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 ...                         # Flux component resource manifests.\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 kustomization.yaml          # Generated kustomization per cluster bootstrap.\n\u2502   \u2502   \u2514\u2500\u2500 kustomization.yaml              # Kustomization per cluster referring all manifests in core and namespace directory.\n\u2502   \u2514\u2500\u2500 staging/\n    \u2502       \u251c\u2500\u2500 flux-system/\n    \u2502       \u2502   \u251c\u2500\u2500 ...\n    \u2502       \u2502   \u2514\u2500\u2500 kustomization.yaml\n    \u2502       \u2514\u2500\u2500 kustomization.yaml\n    \u251c\u2500\u2500 core/\n    \u2502   \u251c\u2500\u2500 base/\n    \u2502   \u2502   \u2514\u2500\u2500 .../                            # One folder per resource type and/or app with its core dependency with prune disabled.\n\u2502   \u2502       \u2514\u2500\u2500 application/                # One folder per application with core manifests.\n\u2502   \u2502           \u2514\u2500\u2500 kustomization.yaml      # Kustomization per core application.\n\u2502   \u2514\u2500\u2500 overlays/\n    \u2502       \u251c\u2500\u2500 production/\n    \u2502       \u2502   \u251c\u2500\u2500 kustomization.yaml          # Kustomization per cluster referencing each core app required.\n\u2502       \u2502   \u2514\u2500\u2500 patch.yaml                  # Optional patch for each environment.\n\u2502       \u2514\u2500\u2500 staging/\n    \u2502           \u251c\u2500\u2500 kustomization.yaml\n    \u2502           \u2514\u2500\u2500 patch.yaml\n    \u2514\u2500\u2500 namespaces/\n        \u251c\u2500\u2500 base/\n        \u2502   \u2514\u2500\u2500 namespace/                      # One folder per namespace containing base resources.\n\u2502       \u251c\u2500\u2500 namespace.yaml              # Namespace manifest.\n\u2502       \u251c\u2500\u2500 kustomization.yaml          # Kustomization per namespace referring all manifests in this current directory.\n\u2502       \u2514\u2500\u2500 application/                # Folder per app containing manifests and patches for each application.\n\u2502           \u2514\u2500\u2500 kustomizaiton.yaml      # Kustomization per app referring all manifests in this directory.\n\u2514\u2500\u2500 overlays/\n            \u251c\u2500\u2500 production/\n            \u2502   \u251c\u2500\u2500 kustomization.yaml          # Kustomization per cluster referencing each namespace and app required.\n\u2502   \u2514\u2500\u2500 patch.yaml                  # Optional patch for each environment.\n\u2514\u2500\u2500 staging/\n                \u251c\u2500\u2500 kustomization.yaml\n                \u2514\u2500\u2500 patch.yaml\n</code></pre>"},{"location":"configuration/repo-structure/#repository-structure-breakdown","title":"Repository Structure Breakdown","text":"<p>This Git repository contains the following directories:</p> <ul> <li>clusters dir contains the Flux configuration per cluster.</li> <li>core dir contains cluster resources that are core prerequisites to the cluster.</li> <li>namespaces dir contains namespaces and application workloads per cluster.</li> </ul> <pre><code>.\n\u251c\u2500\u2500 clusters/\n\u2502   \u251c\u2500\u2500 production\n\u2502   \u2514\u2500\u2500 staging\n\u251c\u2500\u2500 core/\n\u2502   \u251c\u2500\u2500 base\n\u2502   \u2514\u2500\u2500 overlays/\n\u2502       \u251c\u2500\u2500 production\n\u2502       \u2514\u2500\u2500 staging\n\u2514\u2500\u2500 namespaces/\n    \u251c\u2500\u2500 base\n    \u2514\u2500\u2500 overlays/\n        \u251c\u2500\u2500 production\n        \u2514\u2500\u2500 staging\n</code></pre> <p>The clusters/ dir contains configuration for each cluster definition and the infrastructure as code for each relevant cluster where applicable.</p> <p>The core/ dir contains all resources that are prerequisites to namespaces and workloads, this includes resources: CRDs, certain applications like Istio and Gatekeeper that must exist prior to other workloads, and crossplane resources that provisions infrastructure.</p> <p>The namespaces/ configuration is structured into:</p> <ul> <li>namespaces/base/ dir contains namespaces and application workload resources.</li> <li>namespaces/overlays/production/ dir contains the production cluster values and references what base components to deploy.</li> <li>namespaces/overlays/staging/ dir contains the stating cluster values and references what base components to deploy.</li> </ul> <pre><code>.\n\u2514\u2500\u2500 namespaces/\n    \u251c\u2500\u2500 base/\n    \u2502   \u2514\u2500\u2500 namespace/\n    \u2502       \u251c\u2500\u2500 namespace.yaml\n    \u2502       \u251c\u2500\u2500 kustomization.yaml\n    \u2502       \u2514\u2500\u2500 application/\n    \u2502           \u251c\u2500\u2500 helmrelease.yaml\n    \u2502           \u2514\u2500\u2500 kustomizaiton.yaml\n    \u2514\u2500\u2500 overlays/\n        \u251c\u2500\u2500 production/\n        \u2502   \u251c\u2500\u2500 kustomization.yaml\n        \u2502   \u2514\u2500\u2500 patch.yaml\n        \u2514\u2500\u2500 staging/\n            \u2514\u2500\u2500 ...\n</code></pre> <p>In namespaces/base/ dir will be a hierarchy of all namespace/ dirs which will contain application resources. Each cluster overlay includes each namespace and/or application which is explicitly referenced; The base application configuration is defined with the following values:</p> <pre><code>apiVersion: helm.toolkit.fluxcd.io/v2beta1\nkind: HelmRelease\nmetadata:\n  name: metallb\n  namespace: network-system\nspec:\n  interval: 5m\n  chart:\n    spec:\n      chart: metallb\n      version: 2.0.4\n      sourceRef:\n        kind: HelmRepository\n        name: bitnami-charts\n        namespace: flux-system\n      interval: 10m\n  values:\n    configInline:\n      address-pools:\n        - name: default\n          protocol: layer2\n          addresses:\n            - 192.168.1.150-192.168.1.155\n</code></pre> <p>In namespaces/overlays/production/ dir we have a Kustomize patch file(s) with the production cluster specific values:</p> <pre><code>apiVersion: helm.toolkit.fluxcd.io/v2beta1\nkind: HelmRelease\nmetadata:\n  name: metallb\n  namespace: network-system\nspec:\n  values:\n    configInline:\n      address-pools:\n        - name: default\n          protocol: layer2\n          addresses:\n            - 192.168.1.150-192.168.1.155\n</code></pre> <p>Note that whilst using Kustomize we can overwrite default values; in this example the default MetalLB address pool will be patched in the production cluster to a unique pool.</p>"},{"location":"configuration/sealed-secrets/","title":"Sealed Secrets","text":"<p>Work in progress</p> <p>This document is a work in progress.</p> <p>When bootstrapping your cluster for the first time you must store a unique public &amp; private key for your sealed-secrets controller to use for managing your sensitive keys and passwords in your Kubernetes cluster.</p>"},{"location":"configuration/sealed-secrets/#install-the-cli-tool","title":"Install the CLI tool","text":"<p>For all installation methods visit the Sealed Secrets install guide</p> <pre><code>brew install kubeseal\n</code></pre>"},{"location":"configuration/sealed-secrets/#remove-existing-key-cert","title":"Remove Existing Key &amp; Cert","text":"<p>Remove the sealed-secrets master key currently present in this repository</p> <pre><code>rm -f k8s/clusters/&lt;cluster&gt;/secrets/sealed-secret-private-key.enc.yaml\n</code></pre> <p>Remove the sealed-secrets public cert currently present in this repository</p> <pre><code>rm -f k8s/clusters/&lt;cluster&gt;/secrets/sealed-secret-public-cert.yaml\n</code></pre>"},{"location":"configuration/sealed-secrets/#store-new-key-cert","title":"Store New Key &amp; Cert","text":""},{"location":"configuration/sealed-secrets/#private-key","title":"Private Key","text":"<p>Once sealed-secrets has been re-deployed to a running cluster you must store the private key and public cert in this repository.</p> <p>Get the generated sealed-secret private key</p> <pre><code>kubectl get secret -n kube-system -l sealedsecrets.bitnami.com/sealed-secrets-key -o yaml &gt; k8s/clusters/&lt;cluster&gt;/secrets/sealed-secret-private-key.yaml\n</code></pre> <p>Encrypt the sealed-secret private key using SOPs</p> <pre><code>sops --encrypt k8s/clusters/&lt;cluster&gt;/secrets/sealed-secret-private-key.yaml &gt; k8s/clusters/&lt;cluster&gt;/secrets/sealed-secret-private-key.enc.yaml\n</code></pre> <p>Remove unencrypted private key</p> <pre><code>rm -f k8s/clusters/&lt;cluster&gt;/secrets/sealed-secret-private-key.yaml\n</code></pre>"},{"location":"configuration/sealed-secrets/#public-cert","title":"Public Cert","text":"<p>Fetch the generated sealed-secret public cert and store it</p> <pre><code>kubeseal \\\n--controller-name sealed-secrets \\\n--fetch-cert &gt; k8s/clusters/&lt;cluster&gt;/secrets/sealed-secret-public-cert.yaml\n</code></pre>"},{"location":"configuration/sealed-secrets/#encrypt-secrets","title":"Encrypt Secrets","text":"<p>With a newly generated private key from sealed-secrets you will need to re-encrypt all of the existing required secrets.</p> <p>Create an alias for the CLI tool (recommended)</p> <pre><code>alias kubeseal='kubeseal --cert k8s/clusters/&lt;cluster&gt;/secrets/sealed-secret-public-cert.pem --controller-name sealed-secrets --format yaml'\n</code></pre> <p>Encrypt new Kubernetes secret</p> <pre><code>kubeseal &lt; secret.yaml &gt; secret.encrypted.yaml\n</code></pre> <p>Remove the unencrypted secret</p> <p>You must encrypt your secrets with the correct cluster public certificate. For more in-depth instructions the official docs can be found here</p>"},{"location":"configuration/sealed-secrets/#offline-decryption","title":"Offline Decryption","text":"<p>Storing the private key allows an offline decryption, this is not recommended and should only be used in a break-glass scenario when the cluster is down and secrets must be accessed.</p> <p>Unencrypt the sealed-secret private key</p> <pre><code>sops --decrypt k8s/clusters/&lt;cluster&gt;/secrets/sealed-secret-private-key.enc.yaml -oyaml &gt; k8s/clusters/&lt;cluster&gt;/secrets/sealed-secret-private-key.yaml\n</code></pre> <p>Unseal the encrypted secret(s)</p> <pre><code>kubeseal --recovery-unseal --recovery-private-key ./k8s/clusters/&lt;cluster&gt;/secrets/sealed-secret-private-key.yaml &lt; &lt;path-to-file&gt;/secret.encrypted.yaml\n</code></pre> <p>Re-Encrypt the sealed-secret private key</p> <pre><code>sops --encrypt k8s/clusters/&lt;cluster&gt;/secrets/sealed-secret-private-key.yaml &gt; k8s/clusters/&lt;cluster&gt;/secrets/sealed-secret-private-key.enc.yaml\n</code></pre> <p>Remove the unencrypted private key</p> <pre><code>rm -f k8s/clusters/&lt;cluster&gt;/secrets/sealed-secret-private-key.yaml\n</code></pre>"},{"location":"configuration/secret-management/","title":"Secret Management","text":"<p>Work in progress</p> <p>This document is a work in progress.</p>"},{"location":"configuration/secret-management/#requirements","title":"Requirements","text":"<ul> <li>Store encrypted secrets in Git</li> <li>DIFF ciphertext in Git</li> <li>View secret metadata without decryption</li> <li>View secret spec structure without decryption</li> <li>Decrypt secrets from any machine</li> <li>Support multi-cluster encrypt/decrypt keys</li> <li>Support kube RBAC for CRUD operations</li> <li>Support IAM for decryption</li> <li>Secrets decoupled from application configuration</li> <li>Protection against committing unencrypted secrets to Git</li> </ul>"},{"location":"configuration/secret-management/#proposed-solution","title":"Proposed Solution","text":"<p>A combination of Sealed Secrets with SOPs...But why?</p> <p>Justification:</p> <ul> <li>SOPs decryption in conjunction with Flux decrypts secrets on the fly and applies them as encoded Kubernetes secret resources, which reduces the ability to issue permissive RBAC controls to engineers without exposing the secret. Whereas Sealed Secrets would provide the ability to grant permissive RBAC controls to the encrypted custom resource that it provides whilst still protecting the sensitive information.</li> <li>Sealed Secrets can only be decrypted by the operator itself in the cluster or by utilizing the private key. If a cluster becomes unavailable and no longer recoverable you will need to recover these secrets, hence persisting the private key is required, however this key must also be protected and encrypted. SOPs natively integrates with cloud KMS and can encrypt the Sealed Secrets private key.</li> </ul> <p>Utilizing both Sealed Secerets and SOPs meets the following criteria:</p> <ul> <li> Store encrypted secrets in Git</li> </ul> <p>Sealed Secrets allows for secrets to be stored as encrypted values in source control securely. SOPs likewise allows for the private key to be stored as an encrypted value in source control.</p> <ul> <li> DIFF ciphertext in Git</li> </ul> <p>Both Sealed Secrets and SOPs provide the ciphertext in source control which can be versioned and DIFF'ed between changes.</p> <ul> <li> View secret metadata without decryption</li> </ul> <p>Sealed Secrets doesn't encrypted the secret metadata which is useful to view the <code>name</code> and <code>namespace</code> attributes of a secret resource. SOPs by default will encrypt these values.</p> <ul> <li> View secret spec structure without decryption</li> </ul> <p>Both Sealed Secrets and SOPs provide the ability to view the data keys in the secret resource whilst encryption of the values to those keys.</p> <ul> <li> Decrypt secrets from any machine</li> </ul> <p>SOPs integrates with cloud KMS therefore no manual GPG key management is required.</p> <ul> <li> Support multi-cluster encrypt/decrypt keys</li> </ul> <p>Both Sealed Secrets and SOPs provide the capability to manage multi-cluster encrypt/decrypt keys, however, Sealed Secrets public cert ensures ease of use in the OSS environment without additional IAM.</p> <ul> <li> Support kube RBAC for CRUD operations</li> </ul> <p>Sealed Secrets provides a better RBAC model as it allows provisioning CRUD operations to the custom resource, and strict RBAC protection of the secret resource, whilst also allowing permissive RBAC of the encrypted secret custom resource.</p> <ul> <li> Support IAM for decryption</li> </ul> <p>SOPs provides integration with cloud KMS which inherently grants strict IAM models. Access to the private key for offline decryption should be extremely protected and only used in a break-glass scenario.</p> <ul> <li> Secrets decoupled from application configuration</li> </ul> <p>Applications should consume native Kubernetes secrets resources and be decoupled from the implementation of the secret provisioning. Both Sealed Secrets and SOPs can provide his behaviour.</p> <ul> <li> Protection against committing unencrypted secrets to Git</li> </ul> <p>Currently a missing fundamental component is missing in both these tools which prohibits committing unencrypted values to source control. This is a function that will need to be addressed via additional tooling and/or automation, such as pre-commit with the sops-pre-commit hook.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>All contributions are absolutely welcome! An official contribution guide is in the works. Watch this space</p>"},{"location":"contributing/#contributors","title":"Contributors","text":"<p>This project exists thanks to all the people who contribute.</p> <p></p>"},{"location":"faq/","title":"Frequently Asked Questions","text":""},{"location":"faq/#fluxcd-vs-argocd","title":"FluxCD vs. ArgoCD","text":"<p>TODO</p>"},{"location":"installation/","title":"Getting Started","text":"<p>These instructions will assume you have an Kubernetes cluster and want to bootstrap this GitOps repository to it.</p>"},{"location":"installation/#install-the-cli-tool","title":"Install the CLI tool","text":"<p>For all installation methods visit the Flux install guide</p> <pre><code>brew install fluxcd/tap/flux\n</code></pre>"},{"location":"installation/#install-flux","title":"Install Flux","text":"<p>For the full installation guide visit the Flux bootstrap guide</p> <p>Validate the cluster and its connectivity</p> <pre><code>kubectl cluster-info\n</code></pre> <p>Export your GitHub personal access token, username, repository and cluster</p> <pre><code>export GITHUB_TOKEN=&lt;your-token&gt;\nexport GITHUB_USER=&lt;your-username&gt;\nexport GITHUB_REPO=&lt;your-repo&gt;\nexport CLUSTER=&lt;target-cluster&gt;\n</code></pre> <p>Verify that your cluster satisfies the prerequisites</p> <pre><code>flux check --pre\n</code></pre> <p>Run the bootstrap command to install Flux</p> <pre><code>flux bootstrap github \\\n--owner=\"${GITHUB_USER}\" \\\n--repository=\"${GITHUB_REPO}\" \\\n--path=k8s/clusters/\"${CLUSTER}\" \\\n--branch=main \\\n--personal\n</code></pre> <p>Note: If you have network issues with Flux starting you may need to set <code>--network-policies=false</code> in the bootstrap command.</p> <p>You may also use the automated installation script - Either override the defaults in the install script or as environment variables.</p>"},{"location":"sponsor/","title":"Sponsor","text":"<p>If you've found value from any of my open source project(s), you can become a sponsor and also don't forget to star the repo the repository.</p> <p>If you do wish to become a sponsor please visit my official GitHub sponsor page HERE.</p>"},{"location":"sponsor/#backers","title":"Backers","text":"<p>Thank you to all our backers! \ud83d\ude4f [Become a backer]</p> <p></p>"},{"location":"sponsor/#sponsors","title":"Sponsors","text":"<p>Support this project by becoming a sponsor. Your logo will show up here with a link to your website. [Become a sponsor]</p> <p> </p>"}]}